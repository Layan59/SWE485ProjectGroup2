{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16129f9c",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "In this notebook, we apply three clustering algorithms (DBSCAN, Agglomerative Clustering, and K-Means) to group patient data and evaluate their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87cfc1c",
   "metadata": {},
   "source": [
    "## DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ed1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"cleaned_dataset.csv\")  # We load the preprocessed dataset\n",
    "\n",
    "# Drop any unnecessary columns, especially the class label 'Disease'\n",
    "df = df.drop(columns=[col for col in ['nan', 'Disease'] if col in df.columns], errors='ignore')\n",
    "\n",
    "# Standardize the data to normalize scale\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Apply DBSCAN algorithm with pre-defined parameters\n",
    "dbscan = DBSCAN(eps=0.8, min_samples=15)\n",
    "labels = dbscan.fit_predict(df_scaled)\n",
    "\n",
    "# Store the cluster labels\n",
    "df['Cluster'] = labels\n",
    "\n",
    "# Calculate the number of clusters and noise points\n",
    "num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "noise = list(labels).count(-1)\n",
    "\n",
    "# Evaluate clustering using Silhouette Score\n",
    "silhouette = silhouette_score(df_scaled, labels) if num_clusters > 1 else \"N/A\"\n",
    "\n",
    "print(f\"Number of clusters: {num_clusters}\")\n",
    "print(f\"Noise points: {noise}\")\n",
    "print(f\"Silhouette Score: {silhouette}\")\n",
    "print(df['Cluster'].value_counts())\n",
    "\n",
    "# Visualize the clustering result using PCA\n",
    "pca = PCA(n_components=2)\n",
    "data_2d = pca.fit_transform(df_scaled)\n",
    "colors = ['gray' if label == -1 else f'C{label}' for label in labels]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data_2d[:, 0], data_2d[:, 1], c=colors, s=50)\n",
    "plt.title('DBSCAN Clustering Visualization (eps=0.8, min_samples=15)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae0f84",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering (HAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Try different values for the number of clusters and find the best based on silhouette score\n",
    "best_score = -1\n",
    "best_k = 0\n",
    "best_labels = None\n",
    "\n",
    "for k in range(2, 8):\n",
    "    hac = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "    labels = hac.fit_predict(df_scaled)\n",
    "    score = silhouette_score(df_scaled, labels)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = k\n",
    "        best_labels = labels\n",
    "\n",
    "# Assign best clustering result to DataFrame\n",
    "df['Cluster'] = best_labels\n",
    "\n",
    "print(f\"Best number of clusters: {best_k}\")\n",
    "print(f\"Best Silhouette Score: {best_score:.4f}\")\n",
    "print(df['Cluster'].value_counts())\n",
    "\n",
    "# Visualize the HAC clustering result using PCA\n",
    "data_2d = pca.fit_transform(df_scaled)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data_2d[:, 0], data_2d[:, 1], c=best_labels, cmap='Set1', s=50)\n",
    "plt.title(f'HAC Clustering Visualization (k={best_k})')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c564c43f",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1677abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Use the Elbow method to determine optimal k\n",
    "inertia = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(df_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot Elbow Method result\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.xlabel(\"Number of Clusters (K)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"Elbow Method for Optimal K\")\n",
    "plt.show()\n",
    "\n",
    "# Apply KMeans with the selected k\n",
    "k_optimal = 5  # Change this if elbow plot shows a better value\n",
    "kmeans = KMeans(n_clusters=k_optimal, random_state=42, n_init=10)\n",
    "df['Cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "# Evaluate clustering using silhouette score\n",
    "sil_score = silhouette_score(df_scaled, df['Cluster'])\n",
    "print(f\"Silhouette Score: {sil_score:.4f}\")\n",
    "print(df['Cluster'].value_counts())\n",
    "\n",
    "# Visualize the K-Means result\n",
    "data_2d = pca.fit_transform(df_scaled)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data_2d[:, 0], data_2d[:, 1], c=df['Cluster'], cmap='Set2', s=50)\n",
    "plt.title(f'K-Means Clustering Visualization (k={k_optimal})')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66984f",
   "metadata": {},
   "source": [
    "## Conclusion and Comparison\n",
    "\n",
    "- **DBSCAN** detected arbitrary-shaped clusters and identified noise, but may not have formed distinct clusters in sparse data.\n",
    "- **HAC** gave the best silhouette score and produced structured clusters.\n",
    "- **K-Means** was simple and efficient, with reasonable performance based on the elbow method.\n",
    "\n",
    "## How Clustering Helps\n",
    "\n",
    "Clustering helps identify patterns or groupings in the data that could enhance recommendations. For example, patients within the same cluster might share symptoms, and could receive similar treatments or suggestions.\n",
    "\n",
    "If clustering doesnâ€™t directly improve recommendations, it still provides insight into the data structure and variability.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
